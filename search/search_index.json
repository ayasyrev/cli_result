{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cli_results","text":"<p>Simple lib to test results or script runs from command line.  </p> <p> </p>"},{"location":"#install","title":"Install","text":"<p>Install from pypi:  </p> <p><code>pip install cli_result</code></p> <p>Or install from github repo:</p> <p><code>pip install git+https://github.com/ayasyrev/cli_result.git</code></p>"},{"location":"#usage","title":"Usage.","text":"<p>Main purpose test results of examples run. We run all scripts in examples folder and compare results with expected results. Check it at different python versions. So we can be sure that all scripts work and has similar behaviors in different python versions. It's not suitable to run script that supposed to run for a long time or resources are limited. But it's good for quick tests, to check configs and shorts demos (examples).</p> <p>Put your script in examples folder and expected results in results folder. Arguments for tests at file name same as script name + <code>__args.txt.</code></p> <pre><code>from cli_result import check_examples, Cfg\n</code></pre> <pre><code>errors = check_examples()\n</code></pre> <p>This run all scripts in examples folder with arguments from <code>__args.txt</code> file and compare with results at <code>results/</code> folder.  </p> <pre><code>assert errors is None\n</code></pre>"},{"location":"#examples","title":"Examples","text":"<p>We can change examples folder.</p> <pre><code>cfg = Cfg(examples_path=\"../examples/examples_extra/\")\n</code></pre> <p>Check examples at folder:</p> <pre><code>from cli_result import get_examples\n\nexamples = get_examples(cfg=cfg)\n</code></pre> <p>We got list of examples as named tuple example_name, files</p> <pre><code>example = examples[0]\n# name\nprint(example.name)  # or example[0]\n# files\nprint(example.files[0])\nprint(example[1][1])\n</code></pre> output <pre>\n    example_extra_1\n    ../examples/examples_extra/example_extra_1.py\n    ../examples/examples_extra/example_extra_1__alter.py\n\n    </pre>"},{"location":"#run-script","title":"Run script","text":"<p>We can run script and look at result.</p> <pre><code>from cli_result import  run_script\n\nresult = run_script(\n    filename=example[1][0],\n    args=\"--help\",\n)\n</code></pre> <pre><code>print(result.stdout)\n</code></pre> output <pre>\n    usage: example_extra_1.py [-h] [--echo ECHO]\n\n    options:\n      -h, --help   show this help message and exit\n      --echo ECHO\n\n\n    </pre> <pre><code>assert result.stderr == \"\"\n</code></pre>"},{"location":"#load-expected-result","title":"Load expected result.","text":"<pre><code>from cli_result import read_result, get_args\n</code></pre> <p>Load arguments for example. <code>get_args</code> returns list of <code>Args</code></p> <pre><code>args = get_args(example.name, cfg)\n\nprint(args[0])\n</code></pre> output <pre>\n    Args(name='help', list=['--help'])\n\n    </pre> <pre><code>expected = read_result(\n    name=example.name,\n    arg_name=args[0].name,  # or args[0][0]\n    cfg=cfg,\n)\n</code></pre> <p>Now we can compare results.</p> <pre><code>assert result == expected\n</code></pre>"},{"location":"#check-one-example","title":"Check one example.","text":"<p>We can check one example.</p> <pre><code>from cli_result import run_check_example\n\nerrors = run_check_example(\n    example_name=example.name,\n    file_list=example.files,\n    cfg=cfg,\n)\nassert errors is None\n</code></pre> <p>Alternatively we can check one as:</p> <pre><code>errors = check_examples(\n    names=example.name,  # we can send list of names as [name1, name2, ...]\n    cfg=cfg,\n)\nassert errors is None\n</code></pre>"},{"location":"#check-all-examples","title":"Check all examples.","text":"<p>Or check all examples.</p> <pre><code>errors = check_examples(cfg=cfg)\nassert errors is None\n</code></pre>"},{"location":"#check-errors","title":"Check errors","text":"<p>Lets look at example with error.</p> <pre><code>cfg = Cfg(examples_path=\"../tests/examples/examples_errors/\")\n\nerrors = check_examples(cfg=cfg)\nassert errors is not None\nprint(f\"Examples with errors: {len(errors)}, {examples[0].name}: {len(errors[0].list)} errors\")\n</code></pre> output <pre>\n    Examples with errors: 1, example_extra_1: 10 errors\n\n    </pre> <p>Let look at one of errors. We got file name that has error, result of run and expected result. Now we can look for what is wrong.</p> <pre><code>example_error = errors[0]\nprint(example_error.name)\n</code></pre> output <pre>\n    exmpl_1\n\n    </pre> <pre><code>error = example_error.list[4]\nprint(error.argname)\nprint(error.filename)\n</code></pre> output <pre>\n    empty_str\n    ../tests/examples/examples_errors/exmpl_1__err_1.py\n\n    </pre> <p>We can compare result with expected result.</p> <pre><code>print(error.res)\n</code></pre> output <pre>\n    usage: exmpl_1__err_1.py [-h] [--e E]\n    exmpl_1__err_1.py: error: unrecognized arguments: \"\"\n\n\n    </pre> <p>And expected is:</p> <pre><code>print(error.exp)\n</code></pre> output <pre>\n    usage: exmpl_1.py [-h] [--echo ECHO]\n    exmpl_1.py: error: unrecognized arguments: \"\"\n\n\n    </pre>"}]}